SQL is a declarative language
We have to figure out how to find/morph/etc. the data


Programming vs Database
Searching raw text - programming generally faster
CSV file parsing - programming generally faster (not for VERY large files)
Multiple users on one file - database to maintain original and keep logic intact


Indices and data structure makes a database fast
Databases constantly understand queries being run and index the data in a particular way so we can come back to it quickly
It’s like reading a book, then marking the pages which have information you want so you can study later


Index Varieties
B-Tree = equality (<=, ==, etc.) and range queries
Hash = for databases that grow in size
When you insert rows into an already million row database, how do you index those new rows?
Example: a new library has a fixed amount of rows for books. We want to make sure that each category of books can grow if necessary. Instead of being very specific about the amount of rows for each book category, we use a hierarchy (fiction vs nonfiction, then A-Z in fiction and nonfiction).
GeoHash - hierarchy for spatial data based on levels. Level 1 is the lowest level. As levels increase, the bounding box represents a smaller portion of the earth’s surface.
Ex: Level 1 geohash includes a large portion of earth’s surface
Level 6  represents a much smaller square box over earth’s surface
If you didn’t want to use a join (which takes lots of time) you could use a geohash to see if the two areas touch at all

Remember DATE_PART(field, source) to query based on a date column https://www.postgresqltutorial.com/postgresql-date_part/

Create index for faster queries
Syntax
CREATE INDEX  index_name  ON  table_name  USING  index_type 
Index_type = B-tree, hash, etc

Spatial Index
CREATE INDEX index_name ON table_name USING GIST (geom)

Build an index on columns that would generally be useful for querying. We can’t build an index for everything.


create view mn_county_centroid_2 as 
select name as place_name,  ST_setsrid(geom, 4326) as geom,  ST_setsrid(st_centroid, 4326)
from mn_county_centroids mcc 

drop view mn_county_centroids;

alter view mn_county_centroid_2 rename to mn_county_centroid;


--- david’s in class code ----

SELECT name as place_name, ST_Centroid(geom) as geom, ST_Geohash(ST_Centroid(geom),1), ST_Geohash(ST_Centroid(geom), 6), ST_Geohash(ST_Centroid(geom), 20)
from states

GRANT SELECT ON ALL TABLES IN SCHEMA public TO students;
GRANT SELECT ON ALL sequences IN SCHEMA public TO studen


Select * 
from cruts_322_us_climate_big
limit 200
--314496 (climate)
--"40,435,200 big"  


--- March 2009

EXPLAIN 
SELECT * 
FROM cruts_322_us_climate_big
WHERE date_part('year', sample_date) = 2009 and date_part('month', sample_date)::integer = 4 
LIMIT 200
-- 4 secs 992 msec.
-- 4 secs 96 msec.
-- 2 secs 196 msec.  --- March we ran 3 times in arow
-- We switched the month and it was ok 1 secs 698 msec.

--- Remove limit


SELECT * 
FROM cruts_322_us_climate_big
WHERE tmx > 25
LIMIT 200

--- We can create an index
create index cruts_322_us_climate_big_year on cruts_322_us_climate_big USING btree(date_part('year', sample_date))
create index cruts_322_us_climate_big_month on cruts_322_us_climate_big USING btree(date_part('month', sample_date))
create index cruts_322_us_climate_big_year_month on cruts_322_us_climate_big USING btree(date_part('year', sample_date), date_part('month', sample_date))

--- Remove limit
SELECT * 
FROM cruts_322_us_climate_big
WHERE date_part('year', sample_date) = 2009 and date_part('month', sample_date)::integer = 4 
-- 53 secs 840 msec.
-- 1 min 18 secs.

EXPLAIN
SELECT * 
FROM cruts_322_us_climate_big
WHERE date_part('year', sample_date) = 2009


